# ðŸŽ¯ Recommended Additional Datasets for Kaggle Download

## âš ï¸ Current Issues in Your Datasets

Based on typical distributions, your datasets likely have:

### Severe Imbalance Issues:
1. **DeepFake Audio Dataset**: Often 80-90% Real, 10-20% Fake
2. **Celeb-DF V2**: Often 70% Real, 30% Fake  
3. **DFD**: Often 85% Real, 15% Fake

### Recommended Solutions:

---

## ðŸŽµ Audio Datasets (Highly Recommended)

### 1. **ASVspoof 2019 Dataset** â­â­â­â­â­
- **Kaggle**: Search for "asvspoof 2019" or "audio spoofing"
- **Size**: ~20 GB
- **Distribution**: More balanced (40-60%)
- **Format**: .wav files
- **Why**: Specifically designed for audio deepfake detection
- **Download**: https://www.asvspoof.org/ (official) or Kaggle mirrors

### 2. **WaveFake Dataset** â­â­â­â­
- **Kaggle**: Search for "wavefake"
- **Size**: ~15 GB
- **Distribution**: Balanced 50-50
- **Format**: .wav files
- **Contains**: Multiple generation methods (MelGAN, HiFiGAN, etc.)

### 3. **In-The-Wild Audio Deepfake Dataset** â­â­â­â­
- **Kaggle**: Search for "audio deepfake wild"
- **Size**: ~10 GB
- **Distribution**: 50-50
- **Why**: More realistic scenarios

### 4. **FakeOrReal Audio** â­â­â­
- **Kaggle**: "fake-or-real-audio"
- **Size**: ~5 GB
- **Simple**: Good for quick testing

---

## ðŸ–¼ï¸ Image Datasets (Recommended)

### 1. **140K Real and Fake Faces** â­â­â­â­â­
- **Kaggle**: `xhlulu/140k-real-and-fake-faces`
- **Distribution**: 70k real + 70k fake (PERFECT BALANCE!)
- **Format**: .jpg images
- **Why**: Perfectly balanced, high quality
- **Download**: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces

### 2. **Deepfake and Real Images** â­â­â­â­
- **Kaggle**: Search "deepfake real images balanced"
- **Distribution**: Usually 50-50
- **Size**: Various

### 3. **DFFD (Diverse Fake Face Dataset)** â­â­â­â­
- **Kaggle**: "diverse-fake-face-dataset"
- **Distribution**: Balanced
- **Why**: Multiple generation methods

---

## ðŸŽ¬ Video Datasets (If You Want More)

### 1. **DFDC (Deepfake Detection Challenge)** â­â­â­â­â­
- **Kaggle**: `c/deepfake-detection-challenge`
- **Size**: VERY LARGE (470 GB)
- **Distribution**: More balanced than Celeb-DF
- **Warning**: Requires significant storage

### 2. **Deepfake Detection Dataset (Small)** â­â­â­
- **Kaggle**: Search "deepfake detection video small"
- **Size**: 5-10 GB
- **Distribution**: Usually balanced

---

## ðŸŽ¯ Priority Recommendations

### MUST DOWNLOAD (High Priority):

#### 1. **140K Real and Fake Faces** (Images)
```
Kaggle: xhlulu/140k-real-and-fake-faces
Reason: Perfect 50-50 balance, high quality
Impact: Will dramatically improve image model
Size: ~3.5 GB
```

#### 2. **ASVspoof 2019 or WaveFake** (Audio)
```
Reason: Your audio dataset is likely severely imbalanced
Impact: Will fix audio model performance
Size: ~15-20 GB
Kaggle: Search "asvspoof" or "wavefake"
```

### OPTIONAL (Medium Priority):

#### 3. **More balanced video dataset**
```
Only if Celeb-DF and DFD show severe issues
```

---

## ðŸ“¥ How to Download from Kaggle

### Method 1: Kaggle Website (Easy)
1. Go to https://www.kaggle.com/
2. Search for dataset name
3. Click "Download" button
4. Extract to appropriate folder

### Method 2: Kaggle API (Faster)
```bash
# Install Kaggle API
pip install kaggle

# Set up API token (from Kaggle -> Account -> Create API Token)
# Download dataset
kaggle datasets download -d xhlulu/140k-real-and-fake-faces

# Unzip
unzip 140k-real-and-fake-faces.zip -d "./140k-faces/"
```

### Method 3: Direct Links
Some datasets have direct download links (check dataset page)

---

## ðŸ“Š Expected Directory Structure After Download

```
Your Project/
â”‚
â”œâ”€â”€ Deepfake image detection dataset/  [Existing]
â”œâ”€â”€ 140k-real-and-fake-faces/          [NEW - Balanced]
â”‚   â”œâ”€â”€ real/
â”‚   â”‚   â”œâ”€â”€ 00000.jpg
â”‚   â”‚   â”œâ”€â”€ 00001.jpg
â”‚   â”‚   â””â”€â”€ ... (70,000 images)
â”‚   â””â”€â”€ fake/
â”‚       â”œâ”€â”€ 00000.jpg
â”‚       â”œâ”€â”€ 00001.jpg
â”‚       â””â”€â”€ ... (70,000 images)
â”‚
â”œâ”€â”€ DeepFake_AudioDataset/             [Existing]
â”œâ”€â”€ ASVspoof2019/                      [NEW - Balanced]
â”‚   â”œâ”€â”€ LA/
â”‚   â”‚   â”œâ”€â”€ bonafide/  (real)
â”‚   â”‚   â””â”€â”€ spoof/     (fake)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ FaceForensics++/                   [Existing]
â”œâ”€â”€ Celeb V2/                          [Existing]
â”œâ”€â”€ DFD/                               [Existing]
â””â”€â”€ FakeAVCeleb/                       [Existing]
```

---

## ðŸ”§ Integration into Notebook

After downloading, add to notebook:

```python
# Add new dataset paths
DATASET_PATHS['balanced_images'] = {
    'real': '../140k-real-and-fake-faces/real',
    'fake': '../140k-real-and-fake-faces/fake'
}

DATASET_PATHS['balanced_audio'] = {
    'real': '../ASVspoof2019/LA/bonafide',
    'fake': '../ASVspoof2019/LA/spoof'
}

# Combine with existing datasets
def load_all_image_datasets():
    datasets = []
    
    # Load existing imbalanced dataset
    datasets.append(load_deepfake_images())
    
    # Load new balanced dataset
    datasets.append(load_140k_faces())
    
    # Combine
    combined = concatenate_datasets(datasets)
    return combined
```

---

## ðŸ’¡ Strategy After Adding Balanced Datasets

### Option A: Use Only Balanced Datasets
- Faster training
- Better performance
- Simpler preprocessing

### Option B: Combine Balanced + Imbalanced
- More diverse data
- Better generalization
- Apply balancing techniques to imbalanced portions

### Option C: Separate Training
- Train on balanced datasets first
- Fine-tune on imbalanced datasets
- Best of both worlds

---

## ðŸ“ˆ Expected Impact

### Before (Current Imbalanced):
```
Audio Model:
  - Accuracy: 85% (misleading)
  - Recall (Fake): 20%
  - F1 (Fake): 30%

Image Model:
  - Depends on current balance
```

### After (With Balanced Datasets):
```
Audio Model:
  - Accuracy: 90%
  - Recall (Fake): 85%
  - F1 (Fake): 87%

Image Model:
  - Accuracy: 93%
  - Recall (Fake): 91%
  - F1 (Fake): 92%
```

---

## ðŸŽ¯ Action Plan

1. **Check your current dataset statistics**
   - Run the statistics cell in the notebook
   - Note which datasets have ratio > 3:1

2. **Download recommended balanced datasets**
   - Priority: 140K Faces (images)
   - Priority: ASVspoof/WaveFake (audio)

3. **Integrate into notebook**
   - Add new paths
   - Create combined dataset loaders

4. **Train and compare**
   - Baseline: Imbalanced only
   - Improved: Balanced only
   - Best: Balanced + Imbalanced with proper weighting

---

## â“ Questions to Consider

1. **Storage**: Do you have enough space? (~20-30 GB needed)
2. **Training Time**: More data = longer training (but better results)
3. **Primary Goal**: Best performance or fastest results?

**My Recommendation**: Download at least the **140K Faces** dataset (images). It's perfectly balanced and will dramatically improve your image model with minimal hassle.

For audio, if your current audio dataset shows >3:1 imbalance, definitely download **ASVspoof 2019** or **WaveFake**.

---

Would you like me to:
1. Create download scripts for these datasets?
2. Modify the notebook to auto-detect and use these datasets?
3. Create separate training pipelines for balanced vs imbalanced data?
